\documentclass[12pt]{exam}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{mathrsfs}

\usepackage{bm} %bold symbols
\usepackage{hyperref} %add links

%%%%%%%%%%%%%%%%%%%%%%%%%
% 	Define vars here 	%
%%%%%%%%%%%%%%%%%%%%%%%%%

\def\hwName{Homework 11 Part B}
\author{Zhengyu James Pan} %use like \@author
\def\instructor{Dr. Paul Kessenich}
\def\email{jzpan@umich.edu}
\def\dueDate{SUNDAY, April 21}

\newcommand{\reals}{\mathbb{R}}
\newcommand{\realsn}{\reals^{n}}
\newcommand{\nxn}{n\times n}
\newcommand{\realsnxn}{\reals^{\nxn}}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\ints}{\mathbb{Z}}
\newcommand{\transpose}{^\top}

\makeatletter

\begin{document}
%Header
\pagestyle{head}
\firstpageheader{}{}{}
\header{MATH 217}{\hwName}{\thepage}

%Solution formatting
\printanswers
\unframedsolutions

%Top matter
{\parindent0in
\bf
\begin{center}
	MATH 217 W24 - LINEAR ALGEBRA, Section 001 ({\instructor}) \\
	{\hwName} due {\dueDate} at 11:59pm \\
	\@author\ (\href{mailto:\email}{\email})
\end{center}
}

%1
\begin{questions}
\question 
	\begin{parts}
		\part Let $E_0$ denote the 0-eigenspace of $T$. Explicitly describe $E_0$ (as a set).
            \begin{solution}
                \[ E_0 = \left\{ (x_1, 0, x_2, 0, x_3, 0, ...) \mid x_i \in \reals \right\} \]
            \end{solution}
        \part Prove that every real number $\lambda$ is an eigenvalue of $T$. (Hint: explicitly construct an eigenvector $(x_1, x_2, x_3, . . . ) \in V$ . First consider $x_i$ when $i$ is a power of 2.)
            \begin{solution}
                Let $\lambda \in \reals$. Then let \[ s = (1,\  \lambda, \lambda,\  \lambda^2, \lambda^2, \lambda^2, \lambda^2,\  \lambda^3, \lambda^3, \lambda^3, \lambda^3, \lambda^3, \lambda^3, \lambda^3, \lambda^3,\  ...) \]
                be an infinite sequence such that each consecutive power $\lambda^n$ is repeated $n$ times in the sequence, starting from $n=0$. Then
                \begin{align*}
                    T(s) &= (\lambda,\ \lambda^2, \lambda^2,\ \lambda^3, \lambda^3, \lambda^3, \lambda^3, \ \lambda^4, \lambda^4, \lambda^4, \lambda^4, \lambda^4, \lambda^4, \lambda^4, \lambda^4, ...  )\\
                    &= \lambda(s).
                \end{align*}
                So any real number is an eigenvalue of $T$.
            \end{solution}
	\end{parts}

%2
\question 
    \begin{parts}
        \part Let $\mathscr{D}$ be a diagonal $\nxn$ matrix with distinct entries along the diagonal, and let $\mathscr D$ be the subset of $\realsnxn$ consisting of all diagonal matrices. Prove $\mathscr C (D) = \mathscr D$.
            \begin{solution}
                Let the diagonal entries of $D$ be $d_1, ..., d_n$. Let $A \in \mathscr D$, with diagonal entries $a_1, ... a_n$. Then the product \[AD = \begin{bmatrix}
                    a_1 d_1 & 0 & \dots & 0\\
                    0 & a_2 d_2 & 0 & \vdots \\
                    \vdots & 0 & \ddots & 0  \\
                    0 & \dots & 0 & a_n d_n
                \end{bmatrix} = \begin{bmatrix}
                    d_1 a_1 & 0 & \dots & 0\\
                    0 & d_2 a_2 & 0 & \vdots \\
                    \vdots & 0 & \ddots & 0  \\
                    0 & \dots & 0 & d_n a_n
                \end{bmatrix} = DA. \]
                So $\mathscr D \subset \mathscr C (D)$. \\
                \par Let $B \in \mathscr C(D)$ with columns $\vec b_1, ..., \vec b_n$, rows $\vec c_1, ..., \vec c_n$, and element of $i$th row and $j$th column $b_{ij}$. Then
                    \begin{align*}
                        BD &= \begin{bmatrix}
                            \mid &  & \mid \\
                            B (d_1 \vec e_1) & \cdots & B (d_n \vec e_n) \\
                            \mid &  & \mid
                        \end{bmatrix} \\
                        &= \begin{bmatrix}
                            \mid &  & \mid \\
                            d_1 \vec b_1  & \cdots & d_n \vec b_n \\
                            \mid &  & \mid
                        \end{bmatrix} \\\\
                        DB &=\left((DB)\transpose\right)\transpose \\
                        &= \left(B\transpose D\right)\transpose \\
                        &= \begin{bmatrix}
                            \mid &  & \mid \\
                            d_1 \vec c_1\transpose  & \cdots & d_n \vec c_n\transpose \\
                            \mid &  & \mid
                        \end{bmatrix}\transpose \\
                        &= \begin{bmatrix}
                            \rule[3pt]{0.45cm}{0.5pt} & d_1 \vec c_1 & \rule[3pt]{0.45cm}{0.5pt} \\
                             & \vdots & \\
                            \rule[3pt]{0.45cm}{0.5pt} & d_n \vec c_n & \rule[3pt]{0.45cm}{0.5pt}
                        \end{bmatrix}
                    \end{align*}
                where $\vec e_i$ is the $i$th standard basis vector. Since $B \in \mathscr C(D), BD = DB$. Considering arbitrary $b_{ij}$, this means that $d_i b_{ij} = d_j b_{ij}$. 
                \par When $i=j$, then $d_i = d_j$, so $b_{ij}$, a diagonal element of $B$, can be anything.
                \par When $i \neq j$, then $d_i \neq d_j$ since $D$ has distinct diagonal elements. But $d_i b_{ij} = d_j b_{ij}$. So $b_ij = 0$. Note that in this case, $b_ij$ is any non-diagonal element.
                Since only diagonal elements of $B$ can be nonzero, $B$ is diagonal, and $B \in \mathscr D$. So $\mathscr C(D) \subset \mathscr D$.
                \par Thus $\mathscr D = \mathscr C(D).$ 
            \end{solution}
        \part Prove that if $A$ and $B$ are simultaneously diagonalizable $\nxn$ matrices, then $B \in \mathscr C (A)$. 
            \begin{solution}
                We know that $\mathscr D \subset \mathscr C(D)$ for any diagonal matrix $D$ by part (a). (The $\mathscr D \subset \mathscr C (D)$ direction did not depend on the fact that $D$ had distinct diagonal elements.) So then
                \begin{align*}
                    S^{-1} B S S^{-1} A S &= S^{-1} A S S^{-1} B S \\
                    S^{-1} B A S &= S^{-1} A B S \\
                    B A &= A B
                \end{align*}
                Thus $B \in \mathscr C(A)$.
            \end{solution}
        \part Prove that if $A$ and $B$ are $\nxn$ matrices such that $A$ has $n$ distinct eigenvalues and $B \in \mathscr C (A)$, then $A$ and $B$ are simultaneously diagonalizable.
            \begin{solution}
                Let $S$ be an eigenbasis of $A$. Then $S^{-1} A S$, the diagonalized matrix of $A$, has distinct diagonal elements. We know that 
                \begin{align*}
                    B A &= A B \\
                    S^{-1} B A S &= S^{-1} A B S \\
                    S^{-1} B S S^{-1} A S &= S^{-1} A S S^{-1} B S
                \end{align*}
                So $S^{-1} B S \in \mathscr C(S^{-1} A S)$. Then by part (a), since $S^{-1} A S$ is diagonal with distinct entries, $S^{-1} B S$ is diagonal. So $S$ diagonalizes both $B$ and $A$. So $A$ and $B$ are simultaneously diagonalizable.
            \end{solution}
    \end{parts}

\question \begin{parts}
    \part Suppose that $A$ has eigenvalue 0 but is not diagonalizable. Prove that im($A) = E_0$, and conclude from this that $A^2 = 0$.
        \begin{solution}
            The givens imply that det($A - 0I_1) = 0$. So det($A) = 0$. But since it is not diagonalizable, there must be one eigenvalue $\lambda$ of $A$ which does not satisfy almu($\lambda) = $ gemu($\lambda$). Since both almu and gemu are always at least 1, almu $\geq$ gemu, and the sum of almus = $n$; we know almu(0) = 2, and gemu(0) = 1. From this, we infer that the nullity is 1, and the rank is also 1.  The almu also implies that the characteristic equation of $A$ is $x^2 = 0$. \\
            Let $A = \begin{bmatrix*} a & b \\ c & d \end{bmatrix*}.$ Since \begin{align*}
                \text{det}(A - 0I_1) &= (a - x)(d - x) - bc \\
                &= ad - bc - (a + d)x + x^2
            \end{align*} 
            and the characteristic polynomial has no $x^1$ terms, we know that $a + d = 0$, or equivalently that $a = -d$. Additionally, $ad = bc$.
            \par We know that $A$ does not have linearly independent columns, so the columns must be scalar multiples of each other. In fact, since $a = -d$, the ratio of the second column to the first is $\dfrac{d}{c} = \dfrac{-a}{c}$. So then the rref form of $A$ is 
            \[ \begin{bmatrix}
                1 & \dfrac{-a}{c} \\ 0 & 0
            \end{bmatrix} \]
            which has nullspace spanned by $\begin{bmatrix} a \\ b \end{bmatrix}$. But this is also the image of $A$, since both columns of $A$ are scalar multiples of $\begin{bmatrix} a \\ b \end{bmatrix}$. So the image and nullity of $A$ are the same. Thus 
                \[ A^2\vec x = A(A\vec x) = 0 \]
            for any $\vec x \in \reals^2$. Since $A \vec x$ is in ker($A$). So $A^2 = 0$.
        \end{solution}
    \part Let $\lambda \in \reals$ and suppose that $A$ has eigenvalue $\lambda$ but is not diagonalizable. Prove that we have $(A - \lambda I_2)^2$ = 0, and deduce from this that $A \vec v - \lambda \vec v \in E_\lambda$ for every $\vec v \in \reals^2$.
    [Hint: apply part (a) to the matrix $A - \lambda I_2$].
        \begin{solution}
            Since both almu and gemu are always at least 1, almu $\geq$ gemu, and the sum of almus = $n$; we know almu($\lambda$) = 2, and gemu($\lambda) = 1$. So the matrix $A - \lambda I_2$ has an eigenvalue of 0, and nullity 1. So $A - \lambda I_2$ has an eigenvalue of 0 and is not diagonalizable. 
            \par Then by (a), $(A - \lambda I_2)^2 = 0$, and the image of $A - \lambda I_2$ is equal to its 0-eigenspace. The 0-eigenspace of $A - \lambda I_2$ is in turn equal to its own kernel. We know ker($A - \lambda I_2$) is also the $\lambda$-eigenspace of $A$. So for all $\vec v \in \reals^2$, $(A - \lambda I_n) \vec v = A \vec v - \lambda \vec v \in E_\lambda$.
        \end{solution}
    \part Prove that if $A$ has eigenvalue $\lambda$ but is not diagonalizable, then $A$ is similar to $\begin{bmatrix}
        \lambda & 1 \\ 0 & \lambda
    \end{bmatrix}$.
        \begin{solution}
            By (b), we know that $A \vec v - \lambda \vec v \in E_\lambda$ for any vector $\vec v \in \reals^2$. Let $\mathcal B = \{\vec b_1, \vec b_2\},$ where $\vec b_2 \in E_\lambda^\perp$ and $\vec b_1 = A \vec b_2 - \lambda \vec b_2$, which is in $E_\lambda$ by (b). We know that these are linearly independent since they are orthogonal.
            \par Note that this definition of $\mathcal B$ ensures that $A \vec b_1 = \lambda \vec b_1$ and $A \vec b_2 = \vec b_1 + \lambda \vec b_2$.
            \par Then 
                \begin{align*}
                    [A]_\mathcal B &= \begin{bmatrix*} [A\vec b_1]_\mathcal B & [A\vec b_2]_\mathcal B
                    \end{bmatrix*} \\
                    &= \begin{bmatrix}
                        \lambda & 1 \\ 0 & \lambda
                    \end{bmatrix}
                \end{align*}
            So $A$ is similar to $\begin{bmatrix}
                \lambda & 1 \\ 0 & \lambda
            \end{bmatrix}$ by the Change-of-basis of Theorem.
        \end{solution}
    \part Prove that if $A$ does not have any real eigenvalues, then $A$ is similar to a matrix of the form $\lambda Q$ where $Q$ is an orthogonal matrix and $\lambda > 0$.
        \begin{solution}
            We know $A$ has a pair of complex eigenvalues of the form $a \pm bi$. By Worksheet 26 problem 9, $A$ is then similar to the matrix $B = \begin{bmatrix}
                a & b \\ -b & a
            \end{bmatrix}$. Since the columns are already orthogonal, we simply need to normalize them to make the matrix orthogonal, which can be done by dividing by $\lambda = \sqrt{a^2 + b^2}$, which is a positive number. So $Q = \frac{1}{\lambda} B$, and the statement is true.
        \end{solution}
\end{parts}

\question \begin{parts}
    \part Find a matrix $A \in \reals ^{2 \times 2}$ such that $A \begin{bmatrix*} x_n \\ x_{n+1} \end{bmatrix*} = \begin{bmatrix*} x_{n+1} \\ x_{n+2} \end{bmatrix*}$ for every integer $n \geq 0$.
        \begin{solution}
            \[\boxed{A = \begin{bmatrix}
                0 & 1 \\ -13 & 4
            \end{bmatrix} }\]
            \[ A \begin{bmatrix*} x_n \\ x_{n+1} \end{bmatrix*} = \begin{bmatrix*} 0x_n + x_{n+1} \\ -13x_n + 4x_{n+1} \end{bmatrix*} = \begin{bmatrix*} x_{n+1} \\ x_{n+2} \end{bmatrix*} \]
        \end{solution}
    \part Use part (a) to prove by induction that your matrix $A$ satisfies $A^n \begin{bmatrix} 0 \\ 2 \end{bmatrix} = \begin{bmatrix} x_n \\ x_{n+1} \end{bmatrix}$ for every $n \geq 0$.
        \begin{solution}
            Base case: $A^0 \begin{bmatrix} 0 \\ 2 \end{bmatrix} = I_2 \begin{bmatrix} 0 \\ 2 \end{bmatrix}$
            \par \textbf{Inductive step:} Assume that for some integer $n \geq 0$, \[A^n \begin{bmatrix} 0 \\ 2 \end{bmatrix} = \begin{bmatrix} x_n \\ x_{n+1} \end{bmatrix}.\]
            Then by part (a),
            \begin{align*}
                A A^n \begin{bmatrix} 0 \\ 2 \end{bmatrix} &= A^{n+1} \begin{bmatrix} 0 \\ 2 \end{bmatrix} \\
                &= A \begin{bmatrix} x_n \\ x_{n+1} \end{bmatrix} \\
                &= \begin{bmatrix} x_{n+1} \\ x_{n+2} \end{bmatrix}
            \end{align*}
            So if $n$ satisfies the statement, then $n+1$ satisfies the statement.
            Since $n = 0$ satisfies the statement, the statement is true for all $n \geq 0$.
        \end{solution}
    \part Find all (real or complex) eigenvalues and corresponding eigenvectors for $A$.
        \begin{solution}
            \begin{align*}
                \begin{vmatrix}
                    0 - \lambda & 1 \\ -13 & 4 - \lambda 
                \end{vmatrix} &= (- \lambda) ( 4 - \lambda) + 13 \\
                &= \lambda^2 - 4\lambda + 13 \\\\
                \lambda = \frac{4 \pm \sqrt{16 - 52}}{2} &= 2 \pm 3i
                \\\\
                2+3i:\\
                \begin{bmatrix*}
                    - 2 - 3i & 1 \\ -13 & 2 - 3i
                \end{bmatrix*} & \rightarrow \begin{bmatrix*}
                    - 2 - 3i & 1 \\ 0 & 0
                \end{bmatrix*} \\
                E_{2 + 3i} &= \text{span}\left(\begin{bmatrix*}1 \\ 2 + 3i
                \end{bmatrix*}\right)
                \\\\
                2-3i:\\
                \begin{bmatrix*}
                    - 2 + 3i & 1 \\ -13 & 2 + 3i
                \end{bmatrix*} & \rightarrow \begin{bmatrix*}
                    - 2 + 3i & 1 \\ 0 & 0
                \end{bmatrix*} \\
                E_{2 + 3i} &= \text{span}\left(\begin{bmatrix*}1 \\ 2 - 3i
                \end{bmatrix*}\right)
            \end{align*}
        \end{solution}
\end{parts}
\end{questions}

\end{document}